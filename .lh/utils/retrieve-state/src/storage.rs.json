{
    "sourceFile": "utils/retrieve-state/src/storage.rs",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 4,
            "patches": [
                {
                    "date": 1654514095634,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1654514112658,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -143,8 +143,9 @@\n         \"test\",\n         Ratio::new(1, 3),\n         None,\n         verifiable_chunked_hash_activation,\n+        registry,\n     )?)\n }\n \n #[cfg(test)]\n@@ -166,8 +167,9 @@\n             .unwrap()\n             .clone();\n \n         let dir = tempfile::tempdir().unwrap().into_path();\n+        let registry = Registry::new();\n         let mut storage =\n             create_storage(dir, example_block.header.height.into()).expect(\"should create storage\");\n \n         let example_deploy = GetDeployResult::doc_example().deploy.clone();\n"
                },
                {
                    "date": 1654514122589,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -167,11 +167,11 @@\n             .unwrap()\n             .clone();\n \n         let dir = tempfile::tempdir().unwrap().into_path();\n-        let registry = Registry::new();\n-        let mut storage =\n-            create_storage(dir, example_block.header.height.into()).expect(\"should create storage\");\n+        let registry = prometheus::Registry::new();\n+        let mut storage = create_storage(dir, example_block.header.height.into(), &registry)\n+            .expect(\"should create storage\");\n \n         let example_deploy = GetDeployResult::doc_example().deploy.clone();\n \n         let block_with_deploys = BlockWithDeploys {\n"
                },
                {
                    "date": 1654617736878,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -130,9 +130,8 @@\n \n pub fn create_storage(\n     chain_download_path: impl AsRef<Path>,\n     verifiable_chunked_hash_activation: EraId,\n-    registry: &prometheus::Registry,\n ) -> Result<Storage, anyhow::Error> {\n     let chain_download_path = normalize_path(chain_download_path)?;\n     let mut storage_config = StorageConfig::default();\n     storage_config.path = chain_download_path.clone();\n"
                },
                {
                    "date": 1654617752385,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -142,9 +142,9 @@\n         \"test\",\n         Ratio::new(1, 3),\n         None,\n         verifiable_chunked_hash_activation,\n-        registry,\n+        None,\n     )?)\n }\n \n #[cfg(test)]\n@@ -166,9 +166,8 @@\n             .unwrap()\n             .clone();\n \n         let dir = tempfile::tempdir().unwrap().into_path();\n-        let registry = prometheus::Registry::new();\n         let mut storage = create_storage(dir, example_block.header.height.into(), &registry)\n             .expect(\"should create storage\");\n \n         let example_deploy = GetDeployResult::doc_example().deploy.clone();\n"
                }
            ],
            "date": 1654514095634,
            "name": "Commit-0",
            "content": "use std::{\n    env, fs,\n    path::{Path, PathBuf},\n    sync::Arc,\n};\n\nuse lmdb::DatabaseFlags;\n\nuse casper_execution_engine::{\n    core::engine_state::{EngineConfig, EngineState},\n    storage::{\n        global_state::lmdb::LmdbGlobalState, transaction_source::lmdb::LmdbEnvironment,\n        trie_store::lmdb::LmdbTrieStore,\n    },\n};\nuse casper_hashing::Digest;\nuse casper_node::{\n    storage::Storage,\n    types::{Deploy, DeployHash},\n    StorageConfig, WithDir,\n};\nuse casper_types::{EraId, ProtocolVersion};\nuse num_rational::Ratio;\nuse tracing::info;\n\nuse crate::DEFAULT_MAX_READERS;\n\n/// Gets many deploys by hash.\npub fn get_many_deploys_by_hash(\n    storage: &Storage,\n    hashes: &[DeployHash],\n) -> Result<Vec<Deploy>, anyhow::Error> {\n    let mut deploys = vec![];\n    for deploy_hash in hashes {\n        let deploy = match storage.read_deploy_by_hash(*deploy_hash)? {\n            None => {\n                return Err(anyhow::anyhow!(\n                    \"Deploy is present in block but hasn't been downloaded.\"\n                ))\n            }\n            Some(deploy) => deploy,\n        };\n        deploys.push(deploy);\n    }\n    Ok(deploys)\n}\n\n/// Create an lmdb environment at a given path.\nfn create_lmdb_environment(\n    lmdb_path: impl AsRef<Path>,\n    default_max_db_size: usize,\n    manual_sync_enabled: bool,\n) -> Result<Arc<LmdbEnvironment>, anyhow::Error> {\n    let lmdb_environment = Arc::new(LmdbEnvironment::new(\n        &lmdb_path,\n        default_max_db_size,\n        DEFAULT_MAX_READERS,\n        manual_sync_enabled,\n    )?);\n    Ok(lmdb_environment)\n}\n\n/// Loads an existing execution engine.\npub fn load_execution_engine(\n    ee_lmdb_path: impl AsRef<Path>,\n    default_max_db_size: usize,\n    state_root_hash: Digest,\n    manual_sync_enabled: bool,\n) -> Result<(Arc<EngineState<LmdbGlobalState>>, Arc<LmdbEnvironment>), anyhow::Error> {\n    let lmdb_data_file = ee_lmdb_path.as_ref().join(\"data.lmdb\");\n    if !ee_lmdb_path.as_ref().join(\"data.lmdb\").exists() {\n        return Err(anyhow::anyhow!(\n            \"lmdb data file not found at: {}\",\n            lmdb_data_file.display()\n        ));\n    }\n    let lmdb_environment =\n        create_lmdb_environment(&ee_lmdb_path, default_max_db_size, manual_sync_enabled)?;\n    let lmdb_trie_store = Arc::new(LmdbTrieStore::open(&lmdb_environment, None)?);\n    let global_state = LmdbGlobalState::new(\n        Arc::clone(&lmdb_environment),\n        lmdb_trie_store,\n        state_root_hash,\n    );\n    Ok((\n        Arc::new(EngineState::new(global_state, EngineConfig::default())),\n        lmdb_environment,\n    ))\n}\n\n/// Creates a new execution engine.\npub fn create_execution_engine(\n    ee_lmdb_path: impl AsRef<Path>,\n    default_max_db_size: usize,\n    manual_sync_enabled: bool,\n) -> Result<(Arc<EngineState<LmdbGlobalState>>, Arc<LmdbEnvironment>), anyhow::Error> {\n    if !ee_lmdb_path.as_ref().exists() {\n        info!(\n            \"creating new lmdb data dir {}\",\n            ee_lmdb_path.as_ref().display()\n        );\n        fs::create_dir_all(&ee_lmdb_path)?;\n    }\n    fs::create_dir_all(&ee_lmdb_path)?;\n    let lmdb_environment =\n        create_lmdb_environment(&ee_lmdb_path, default_max_db_size, manual_sync_enabled)?;\n    lmdb_environment.env().sync(true)?;\n\n    let lmdb_trie_store = Arc::new(LmdbTrieStore::new(\n        &lmdb_environment,\n        None,\n        DatabaseFlags::empty(),\n    )?);\n    let global_state = LmdbGlobalState::empty(Arc::clone(&lmdb_environment), lmdb_trie_store)?;\n\n    Ok((\n        Arc::new(EngineState::new(global_state, EngineConfig::default())),\n        lmdb_environment,\n    ))\n}\n\npub fn normalize_path(path: impl AsRef<Path>) -> Result<PathBuf, anyhow::Error> {\n    let path = path.as_ref();\n    if path.is_absolute() {\n        Ok(path.into())\n    } else {\n        Ok(env::current_dir()?.join(path))\n    }\n}\n\npub fn create_storage(\n    chain_download_path: impl AsRef<Path>,\n    verifiable_chunked_hash_activation: EraId,\n    registry: &prometheus::Registry,\n) -> Result<Storage, anyhow::Error> {\n    let chain_download_path = normalize_path(chain_download_path)?;\n    let mut storage_config = StorageConfig::default();\n    storage_config.path = chain_download_path.clone();\n    Ok(Storage::new(\n        &WithDir::new(chain_download_path, storage_config),\n        None,\n        ProtocolVersion::from_parts(0, 0, 0),\n        \"test\",\n        Ratio::new(1, 3),\n        None,\n        verifiable_chunked_hash_activation,\n    )?)\n}\n\n#[cfg(test)]\nmod tests {\n    use crate::{\n        get_block_by_identifier, put_block_with_deploys, storage::create_storage, BlockWithDeploys,\n    };\n    use casper_node::rpcs::{\n        chain::{BlockIdentifier, GetBlockResult},\n        docs::DocExample,\n        info::GetDeployResult,\n    };\n\n    #[test]\n    fn block_with_deploys_round_trip_lmdb() {\n        let example_block = GetBlockResult::doc_example()\n            .block\n            .as_ref()\n            .unwrap()\n            .clone();\n\n        let dir = tempfile::tempdir().unwrap().into_path();\n        let mut storage =\n            create_storage(dir, example_block.header.height.into()).expect(\"should create storage\");\n\n        let example_deploy = GetDeployResult::doc_example().deploy.clone();\n\n        let block_with_deploys = BlockWithDeploys {\n            block: example_block.clone(),\n            transfers: vec![example_deploy.clone()],\n            deploys: vec![],\n        };\n\n        put_block_with_deploys(&mut storage, &block_with_deploys).unwrap();\n        let stored_block =\n            get_block_by_identifier(&storage, &BlockIdentifier::Hash(example_block.hash));\n        assert!(matches!(stored_block, Ok(Some(ref _block))));\n\n        let stored_block_by_height = get_block_by_identifier(\n            &storage,\n            &BlockIdentifier::Height(example_block.header.height),\n        );\n        assert!(matches!(stored_block, Ok(Some(ref _block))));\n\n        assert_eq!(\n            stored_block.unwrap().unwrap(),\n            stored_block_by_height.unwrap().unwrap()\n        );\n\n        let stored_deploy = storage.read_deploy_by_hash(*example_deploy.id());\n        assert!(matches!(stored_deploy, Ok(Some(_deploy))));\n    }\n}\n"
        }
    ]
}